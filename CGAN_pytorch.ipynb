{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CGAN-pytorch",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxucnXmrPmvwTLzn1XVOWh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/owemecoffee/ai-learn/blob/main/CGAN_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CGAN Lab\n",
        "This notebook follows [A PyTorch CGAN Tutorial](https://learnopencv.com/deep-convolutional-gan-in-pytorch-and-tensorflow/) and aims at understand CGAN process. More will be covered below.\n",
        "\n",
        "TODO:\n",
        "\n",
        "\n",
        "*   显示每一次生成器生成的图片\n",
        "*   按循环顺序给出每一轮的损失\n",
        "\n"
      ],
      "metadata": {
        "id": "AT84q8_u9NZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process Fake Dataset"
      ],
      "metadata": {
        "id": "1CLY5AR4_eFT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s5v8zVmeLgjk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision.transforms as transforms\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset"
      ],
      "metadata": {
        "id": "md8qXZbU_twQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset, keep image size at (3,64,64) and 2 classes.\n",
        "train_dataset = torchvision.datasets.FakeData(\n",
        "    image_size = (3,64,64)\n",
        "    ,num_classes =2\n",
        "    ,transform=transforms.Compose([\n",
        "        transforms.ToTensor() #turn to tensor\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "XDQsY6VUOUzk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The dataset has :\",len(train_dataset),\" items.\")\n",
        "print(\"With those \",np.unique(train_dataset.num_classes),\" targets.\")\n",
        "\n",
        "#show one sample\n",
        "sample = next(iter(train_dataset))\n",
        "image, label = sample\n",
        "plt.imshow(image)\n",
        "print(\"Label : \", label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLumYlKSJN1_",
        "outputId": "4585a6d1-ca44-494d-ddd4-7f809918aaa9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has : 1000  items.\n",
            "With those  [2]  targets.\n",
            "Label :  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "torchvision.transforms.Compose\n",
        "```\n",
        "To composes several transforms together. \n",
        "\n"
      ],
      "metadata": {
        "id": "0iBS89Qn_KhD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing\n",
        "Use normalization. Mapping pixel values between [-1, 1] have proven to be useful while training GANs."
      ],
      "metadata": {
        "id": "I0aQsixO_xS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#process images, compose \n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    #RGB images has 3 values each for  using the mean and standard deviation\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "id": "BHNVWViuLl6v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight Initialization\n",
        "*   Used for generator and distriminator.\n",
        "*   Convolution-layer weights are initialized from a zero-centered normal distribution, with a standard deviation of 0.02.\n",
        "\n",
        "* batch-normalization layer weights are initialized with a normal distribution, having mean 1 and a standard deviation of 0.02. The bias is initialized with zeros."
      ],
      "metadata": {
        "id": "zzIKYI4dAOgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "        torch.nn.init.zeros_(m.bias)    "
      ],
      "metadata": {
        "id": "-WUTlFF1Ll9N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator\n",
        "The generator is a fully-convolutional network that inputs a noise vector (latent_dim) to output an image of 3 x 64 x 64. "
      ],
      "metadata": {
        "id": "VZfO1CCVM8QF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # Block 1:input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(3, 64 * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(64 * 8),\n",
        "            nn.ReLU(True),\n",
        "            # Block 2: input is (64 * 8) x 4 x 4\n",
        "            nn.ConvTranspose2d(64 * 8, 64 * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64 * 4),\n",
        "            nn.ReLU(True),\n",
        "            # Block 3: input is (64 * 4) x 8 x 8\n",
        "            nn.ConvTranspose2d(64 * 4, 64 * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64 * 2),\n",
        "            nn.ReLU(True),\n",
        "            # Block 4: input is (64 * 2) x 16 x 16\n",
        "            nn.ConvTranspose2d(64 * 2, 64, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            # Block 5: input is (64) x 32 x 32\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # Output: output is (3) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.main(input)\n",
        "        return output    "
      ],
      "metadata": {
        "id": "Tpj4UQzNLl_7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discriminator\n",
        "\n",
        "设计的理由？"
      ],
      "metadata": {
        "id": "cq4qvTEsNGq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "torch.nn.Conv2d\n",
        "```\n",
        "parameters: in_channel, out_channel, kernel size, stride, padding, bias\n",
        "\n"
      ],
      "metadata": {
        "id": "AguiGif2DDrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "LeakyReLU()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "6sI87AyVDfZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator Model Class Definition\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # Block 1: input is (3) x 64 x 64\n",
        "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # Block 2: input is (64) x 32 x 32\n",
        "            nn.Conv2d(64, 64 * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64 * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # Block 3: input is (64*2) x 16 x 16\n",
        "            nn.Conv2d(64 * 2, 64 * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64 * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # Block 4: input is (64*4) x 8 x 8\n",
        "            nn.Conv2d(64 * 4, 64 * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64 * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # Block 5: input is (64*8) x 4 x 4\n",
        "            nn.Conv2d(64 * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Flatten()\n",
        "            # Output: 1\n",
        "        )\n",
        "\n",
        "    #fed an image, returns the output 1 (the image is real) or 0 (it is fake).\n",
        "    def forward(self, input):\n",
        "        output = self.main(input)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "eqI6WX2jLmBq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "#the generator and discriminator models are moved to GPU and initializes all the parametric layers.\n",
        "generator = Generator().to(device)\n",
        "generator.apply(weights_init)\n",
        "discriminator = Discriminator().to(device)\n",
        "discriminator.apply(weights_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkHerTPILmDy",
        "outputId": "a8201a54-ae11-40d8-fc55-92a1b60c36ae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (main): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (12): Sigmoid()\n",
              "    (13): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_loss = nn.BCELoss() "
      ],
      "metadata": {
        "id": "kGCMTvvtLmHb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output, label):\n",
        "    gen_loss = adversarial_loss(fake_output, label)\n",
        "    print(gen_loss)\n",
        "    return gen_loss"
      ],
      "metadata": {
        "id": "8pjh9bCDLmJ8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(output, label):\n",
        "    disc_loss = adversarial_loss(output, label)\n",
        "    print(disc_loss)\n",
        "    return disc_loss"
      ],
      "metadata": {
        "id": "41KPa9nxLmMT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adam Optimizer\n"
      ],
      "metadata": {
        "id": "XGklx2TsEfHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0002 \n",
        "G_optimizer = optim.Adam(generator.parameters(), lr = learning_rate, betas=(0.5, 0.999))\n",
        "D_optimizer = optim.Adam(discriminator.parameters(), lr = learning_rate, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "AvWW4V6GLmO6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "5Exg9OfZEzmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "torch.randn\n",
        "```\n",
        "Returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1. \n",
        "\n",
        "parameter: size\n"
      ],
      "metadata": {
        "id": "Nxmbjk8nGRF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Discriminator"
      ],
      "metadata": {
        "id": "ISfxxWKTIU_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 100): \n",
        "    D_loss_list, G_loss_list = [], []\n",
        "   \n",
        "    for index, (real_images, _) in enumerate(train_loader):\n",
        "      #enumerate: count list with index\n",
        "      D_optimizer.zero_grad()\n",
        "      real_images = real_images.to(device)\n",
        "      \n",
        "      real_target = Variable(torch.ones(real_images.size(0)).to(device))\n",
        "      fake_target = Variable(torch.zeros(real_images.size(0)).to(device))\n",
        "\n",
        "      #pass the real images through a discriminator, calculate the loss D_real_loss, \n",
        "      #and then backpropagate it through the discriminator network.\n",
        "      output = discriminator(real_images)\n",
        "      real_target = torch.reshape(real_target,(10,1))\n",
        "      D_real_loss = discriminator_loss(output, real_target)\n",
        "      D_real_loss.backward()\n",
        " \n",
        "      noise_vector = torch.randn(real_images.size(0), 3, 1, 1, device=device)  \n",
        "      noise_vector = noise_vector.to(device)\n",
        "\n",
        "      #randomy produce noise tensor to generate images.\n",
        "      generated_image = generator(noise_vector)\n",
        "      output = discriminator(generated_image.detach())\n",
        "      fake_target = torch.reshape(fake_target,(10,1))\n",
        "      D_fake_loss = discriminator_loss(output,fake_target)\n",
        "\n",
        "      # train discriminator with fake loss\n",
        "      D_fake_loss.backward()\n",
        "      \n",
        "      D_total_loss = D_real_loss + D_fake_loss\n",
        "      D_loss_list.append(D_total_loss)\n",
        "      \n",
        "      # updates the discriminator parameters, \n",
        "      D_optimizer.step()\n"
      ],
      "metadata": {
        "id": "qakhrQxhLmVt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Generator"
      ],
      "metadata": {
        "id": "96Af48E_IaTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train G on D's output\n",
        "G_optimizer.zero_grad()\n",
        "gen_output = discriminator(generated_image)\n",
        "G_loss = generator_loss(gen_output, real_target)\n",
        "G_loss_list.append(G_loss)\n",
        "G_loss.backward()\n",
        "G_optimizer.step()"
      ],
      "metadata": {
        "id": "euElEtcqLmYM"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}